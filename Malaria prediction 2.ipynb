{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network\n",
    "\n",
    "# Installing Theano\n",
    "# pip install --upgrade --no-deps git+git://github.com/Theano/Theano.git\n",
    "\n",
    "# Installing Tensorflow\n",
    "# Install Tensorflow from the website: https://www.tensorflow.org/versions/r0.12/get_started/os_setup.html\n",
    "\n",
    "# Installing Keras\n",
    "# pip install --upgrade keras\n",
    "\n",
    "# Part 1 - Building the CNN\n",
    "\n",
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "\n",
    "# Initialising the CNN\n",
    "classifier = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Part 2 - Fitting the CNN to the images\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/training_set',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/test_set',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n",
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 - Convolution\n",
    "classifier.add(Convolution2D(32, 3, 3, input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "# Step 2 - Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Adding a second convolutional layer\n",
    "classifier.add(Convolution2D(32, 3, 3, activation = 'relu'))\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "# Step 3 - Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "# Step 4 - Full connection\n",
    "classifier.add(Dense(output_dim = 128, activation = 'relu'))\n",
    "classifier.add(Dense(output_dim = 1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Compiling the CNN\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "training_set = train_datagen.flow_from_directory('cell_images/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5512 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_set = test_datagen.flow_from_directory('cell_images/valid',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\md sohaib uddin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  \"\"\"\n",
      "C:\\Users\\md sohaib uddin\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras.pre..., validation_data=<keras.pre..., steps_per_epoch=250, epochs=25, validation_steps=2000)`\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "250/250 [==============================] - 124s 498ms/step - loss: 0.6854 - accuracy: 0.5501 - val_loss: 0.6402 - val_accuracy: 0.5810\n",
      "Epoch 2/25\n",
      "250/250 [==============================] - 124s 495ms/step - loss: 0.6674 - accuracy: 0.5951 - val_loss: 0.8906 - val_accuracy: 0.5620\n",
      "Epoch 3/25\n",
      "250/250 [==============================] - 124s 497ms/step - loss: 0.6541 - accuracy: 0.6189 - val_loss: 0.6186 - val_accuracy: 0.6280\n",
      "Epoch 4/25\n",
      "250/250 [==============================] - 109s 437ms/step - loss: 0.6422 - accuracy: 0.6258 - val_loss: 0.6061 - val_accuracy: 0.6782\n",
      "Epoch 5/25\n",
      "250/250 [==============================] - 121s 483ms/step - loss: 0.6326 - accuracy: 0.6401 - val_loss: 0.6112 - val_accuracy: 0.6944\n",
      "Epoch 6/25\n",
      "250/250 [==============================] - 127s 506ms/step - loss: 0.5640 - accuracy: 0.7105 - val_loss: 0.4286 - val_accuracy: 0.7280\n",
      "Epoch 7/25\n",
      "250/250 [==============================] - 151s 605ms/step - loss: 0.4976 - accuracy: 0.7559 - val_loss: 0.4055 - val_accuracy: 0.7989\n",
      "Epoch 8/25\n",
      "250/250 [==============================] - 136s 545ms/step - loss: 0.4284 - accuracy: 0.8017 - val_loss: 0.2330 - val_accuracy: 0.8274\n",
      "Epoch 9/25\n",
      "250/250 [==============================] - 137s 550ms/step - loss: 0.3621 - accuracy: 0.8402 - val_loss: 0.3700 - val_accuracy: 0.8720\n",
      "Epoch 10/25\n",
      "250/250 [==============================] - 145s 580ms/step - loss: 0.3085 - accuracy: 0.8733 - val_loss: 0.2210 - val_accuracy: 0.9096\n",
      "Epoch 11/25\n",
      "250/250 [==============================] - 160s 641ms/step - loss: 0.2634 - accuracy: 0.8969 - val_loss: 0.3818 - val_accuracy: 0.8753\n",
      "Epoch 12/25\n",
      "250/250 [==============================] - 161s 644ms/step - loss: 0.2483 - accuracy: 0.9075 - val_loss: 0.2393 - val_accuracy: 0.9288\n",
      "Epoch 13/25\n",
      "250/250 [==============================] - 160s 639ms/step - loss: 0.2374 - accuracy: 0.9134 - val_loss: 0.1094 - val_accuracy: 0.9131\n",
      "Epoch 14/25\n",
      "250/250 [==============================] - 157s 626ms/step - loss: 0.2293 - accuracy: 0.9156 - val_loss: 0.2000 - val_accuracy: 0.9419\n",
      "Epoch 15/25\n",
      "250/250 [==============================] - 163s 653ms/step - loss: 0.2217 - accuracy: 0.9156 - val_loss: 0.1554 - val_accuracy: 0.9197\n",
      "Epoch 16/25\n",
      "250/250 [==============================] - 163s 652ms/step - loss: 0.2053 - accuracy: 0.9279 - val_loss: 0.2229 - val_accuracy: 0.9454\n",
      "Epoch 17/25\n",
      "250/250 [==============================] - 154s 616ms/step - loss: 0.1935 - accuracy: 0.9308 - val_loss: 0.0274 - val_accuracy: 0.9493\n",
      "Epoch 18/25\n",
      "250/250 [==============================] - 155s 622ms/step - loss: 0.1881 - accuracy: 0.9306 - val_loss: 0.2848 - val_accuracy: 0.9409\n",
      "Epoch 19/25\n",
      "250/250 [==============================] - 160s 641ms/step - loss: 0.1814 - accuracy: 0.9342 - val_loss: 0.2138 - val_accuracy: 0.9400\n",
      "Epoch 20/25\n",
      "250/250 [==============================] - 163s 650ms/step - loss: 0.1944 - accuracy: 0.9274 - val_loss: 0.0758 - val_accuracy: 0.9431\n",
      "Epoch 21/25\n",
      "250/250 [==============================] - 156s 625ms/step - loss: 0.1820 - accuracy: 0.9329 - val_loss: 0.2715 - val_accuracy: 0.9440\n",
      "Epoch 22/25\n",
      "250/250 [==============================] - 140s 561ms/step - loss: 0.1753 - accuracy: 0.9384 - val_loss: 0.1008 - val_accuracy: 0.9433\n",
      "Epoch 23/25\n",
      "250/250 [==============================] - 125s 498ms/step - loss: 0.1754 - accuracy: 0.9365 - val_loss: 0.1650 - val_accuracy: 0.9417\n",
      "Epoch 24/25\n",
      "250/250 [==============================] - 142s 569ms/step - loss: 0.1792 - accuracy: 0.9352 - val_loss: 0.0642 - val_accuracy: 0.9468\n",
      "Epoch 25/25\n",
      "250/250 [==============================] - 157s 629ms/step - loss: 0.1755 - accuracy: 0.9364 - val_loss: 0.0902 - val_accuracy: 0.9481\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x115cdfd72b0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.fit_generator(training_set,\n",
    "                         samples_per_epoch = 8000,\n",
    "                         nb_epoch = 25,\n",
    "                         validation_data = test_set,\n",
    "                         nb_val_samples = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninfected\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x115d04b9e10>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_image1 = image.load_img('cell_images/random1.png', target_size = (64,64))\n",
    "test_image = image.img_to_array(test_image1)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "training_set.class_indices\n",
    "if result[0][0] >= 0.5:\n",
    "    prediction = 'Uninfected'\n",
    "else: \n",
    "    prediction = 'Infected'\n",
    "print(prediction)\n",
    "\n",
    "plt.imshow(test_image1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
